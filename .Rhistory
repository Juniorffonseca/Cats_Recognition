hist <- model %>% fit(
train_images,
steps_per_epoch = train_images$n %/% batch_size,
epochs = epochs,
validation_data = validation_images,
validation_steps = validation_images$n %/% batch_size,
verbose = 2
)
# Carregando pacotes -----------------------------------------------------------
library(tidyverse)
library(keras)
library(tensorflow)
library(reticulate)
# Training
setwd("C:/Users/anonb/Documents/Cats_Recognition")
label_list <- dir("dados_brutos/")
output_n <- length(label_list)
save(label_list, file="label_list.R")
# Tamanho das imagens
width <- 64
height <- 64
target_size <- c(width, height)
rgb <- 3 #color channels
path_train <- "dados_brutos/"
train_data_gen <- image_data_generator(rescale = 1/255,
validation_split = .2)
train_images <- flow_images_from_directory(path_train,
train_data_gen,
subset = 'training',
target_size = target_size,
class_mode = "categorical",
shuffle=F,
seed = 2021)
validation_images <- flow_images_from_directory(path_train,
train_data_gen,
subset = 'validation',
target_size = target_size,
class_mode = "categorical",
seed = 2021)
mod_base <- application_xception(weights = 'imagenet',
include_top = FALSE, input_shape = c(71, 71, 3))
freeze_weights(mod_base)
model_function <- function(learning_rate = 0.001,
dropoutrate=0.2, n_dense=1024){
k_clear_session()
model <- keras_model_sequential() %>%
mod_base %>%
layer_global_average_pooling_2d() %>%
layer_dense(units = n_dense) %>%
layer_activation("relu") %>%
layer_dropout(dropoutrate) %>%
layer_dense(units=output_n, activation="softmax")
model %>% compile(
loss = "categorical_crossentropy",
optimizer = optimizer_adam(learning_rate = 0.001),
metrics = "accuracy"
)
return(model)
}
model <- model_function()
model
batch_size <- 32
epochs <- 6
hist <- model %>% fit(
train_images,
steps_per_epoch = train_images$n %/% batch_size,
epochs = epochs,
validation_data = validation_images,
validation_steps = validation_images$n %/% batch_size,
verbose = 2
)
# Carregando pacotes -----------------------------------------------------------
library(tidyverse)
library(keras)
library(tensorflow)
library(reticulate)
# Training
setwd("C:/Users/anonb/Documents/Cats_Recognition")
label_list <- dir("dados_brutos/")
output_n <- length(label_list)
save(label_list, file="label_list.R")
# Tamanho das imagens
width <- 64
height <- 64
target_size <- c(width, height)
rgb <- 3 #color channels
path_train <- "dados_brutos/"
train_data_gen <- image_data_generator(rescale = 1/255,
validation_split = .2)
train_images <- flow_images_from_directory(path_train,
train_data_gen,
subset = 'training',
target_size = target_size,
class_mode = "categorical",
shuffle=F,
seed = 2021)
validation_images <- flow_images_from_directory(path_train,
train_data_gen,
subset = 'validation',
target_size = target_size,
class_mode = "categorical",
seed = 2021)
mod_base <- application_xception(weights = 'imagenet',
include_top = FALSE, input_shape = c(71, 71, 3))
freeze_weights(mod_base)
model_function <- function(learning_rate = 0.001,
dropoutrate=0.2, n_dense=1024){
k_clear_session()
model <- keras_model_sequential() %>%
mod_base %>%
layer_global_average_pooling_2d() %>%
layer_dense(units = n_dense) %>%
layer_activation("relu") %>%
layer_dropout(dropoutrate) %>%
layer_dense(units=output_n, activation="softmax")
model %>% compile(
loss = "categorical_crossentropy",
optimizer = optimizer_adam(learning_rate = 0.001),
metrics = "accuracy"
)
return(model)
}
model <- model_function()
model
batch_size <- 32
epochs <- 6
hist <- model %>% fit(
train_images,
steps_per_epoch = train_images$n %/% batch_size,
epochs = epochs,
validation_data = validation_images,
validation_steps = validation_images$n %/% batch_size,
verbose = 2
)
# Carregando pacotes -----------------------------------------------------------
library(tidyverse)
# Carregando pacotes -----------------------------------------------------------
library(tidyverse)
library(keras)
library(tensorflow)
library(reticulate)
# Training
setwd("C:/Users/anonb/Documents/Cats_Recognition")
label_list <- dir("dados_brutos/")
output_n <- length(label_list)
save(label_list, file="label_list.R")
# Tamanho das imagens
width <- 64
height <- 64
target_size <- c(width, height)
rgb <- 3 #color channels
path_train <- "dados_brutos/"
train_data_gen <- image_data_generator(rescale = 1/255,
validation_split = .2)
train_images <- flow_images_from_directory(path_train,
train_data_gen,
subset = 'training',
target_size = target_size,
class_mode = "categorical",
shuffle=F,
seed = 2021)
validation_images <- flow_images_from_directory(path_train,
train_data_gen,
subset = 'validation',
target_size = target_size,
class_mode = "categorical",
seed = 2021)
mod_base <- application_xception(weights = 'imagenet',
include_top = FALSE, input_shape = c(71, 71, 3))
freeze_weights(mod_base)
model_function <- function(learning_rate = 0.001,
dropoutrate=0.2, n_dense=1024){
k_clear_session()
model <- keras_model_sequential() %>%
mod_base %>%
layer_global_average_pooling_2d() %>%
layer_dense(units = n_dense) %>%
layer_activation("relu") %>%
layer_dropout(dropoutrate) %>%
layer_dense(units=output_n, activation="softmax")
model %>% compile(
loss = "categorical_crossentropy",
optimizer = optimizer_adam(learning_rate = 0.001),
metrics = "accuracy"
)
return(model)
}
model <- model_function()
model
batch_size <- 32
epochs <- 6
hist <- model %>% fit(
train_images,
steps_per_epoch = train_images$n %/% batch_size,
epochs = epochs,
validation_data = validation_images,
validation_steps = validation_images$n %/% batch_size,
verbose = 2
)
reticulate::py_last_error()
# Carregando pacotes -----------------------------------------------------------
library(tidyverse)
library(keras)
library(tensorflow)
library(reticulate)
# Training
setwd("C:/Users/anonb/Documents/Cats_Recognition")
label_list <- dir("dados_brutos/")
output_n <- length(label_list)
save(label_list, file="label_list.R")
# Tamanho das imagens
width <- 224
height <- 224
target_size <- c(width, height)
rgb <- 3 #color channels
path_train <- "dados_brutos/"
train_data_gen <- image_data_generator(rescale = 1/255,
validation_split = .2)
train_images <- flow_images_from_directory(path_train,
train_data_gen,
subset = 'training',
target_size = target_size,
class_mode = "categorical",
shuffle=F,
seed = 2021)
validation_images <- flow_images_from_directory(path_train,
train_data_gen,
subset = 'validation',
target_size = target_size,
class_mode = "categorical",
seed = 2021)
mod_base <- application_xception(weights = 'imagenet',
include_top = FALSE, input_shape = c(71, 71, 3))
freeze_weights(mod_base)
model_function <- function(learning_rate = 0.001,
dropoutrate=0.2, n_dense=1024){
k_clear_session()
model <- keras_model_sequential() %>%
mod_base %>%
layer_global_average_pooling_2d() %>%
layer_dense(units = n_dense) %>%
layer_activation("relu") %>%
layer_dropout(dropoutrate) %>%
layer_dense(units=output_n, activation="softmax")
model %>% compile(
loss = "categorical_crossentropy",
optimizer = optimizer_adam(learning_rate = 0.001),
metrics = "accuracy"
)
return(model)
}
model <- model_function()
model
batch_size <- 32
epochs <- 6
hist <- model %>% fit(
train_images,
steps_per_epoch = train_images$n %/% batch_size,
epochs = epochs,
validation_data = validation_images,
validation_steps = validation_images$n %/% batch_size,
verbose = 2
)
test_images <- flow_images_from_directory(path_train,
validation_images,
target_size = target_size,
class_mode = "categorical",
classes = label_list,
shuffle = F,
seed = 2021)
test_images <- flow_images_from_directory(path_train,
validation_images,
target_size = target_size,
class_mode = "categorical",
classes = label_list,
shuffle = F,
seed = 2021)
View(validation_images)
model %>% evaluate_generator(validation_images,
steps = validation_images$n)
model %>% evaluate(validation_images,
steps = validation_images$n)
validation_steps = len(validation_images)/batch_size
?len
?length
validation_steps = length(validation_images)/batch_size
model %>% evaluate(validation_images,
steps = validation_images$n)
?evaluate
model %>% evaluate(validation_images,
steps = validation_images$n, epochs = epochs, steps_per_epoch = validation_images %/% batch_size)
View(hist)
output_n <- length(label_list)
train_images <- flow_images_from_directory(path_train,
train_data_gen,
subset = 'training',
target_size = target_size,
class_mode = "categorical",
shuffle=F,
seed = 2021)
validation_images <- flow_images_from_directory(path_train,
train_data_gen,
subset = 'validation',
target_size = target_size,
class_mode = "categorical",
seed = 2021)
mod_base <- application_xception(weights = 'imagenet',
include_top = FALSE, input_shape = c(71, 71, 3))
freeze_weights(mod_base)
model %>% evaluate(validation_images,
steps = validation_images$n, epochs = epochs, steps_per_epoch = validation_images %/% batch_size)
model %>% evaluate(validation_images)
# Carregando pacotes -----------------------------------------------------------
library(tidyverse)
library(keras)
library(tensorflow)
library(reticulate)
# Training
setwd("C:/Users/anonb/Documents/Cats_Recognition")
label_list <- dir("dados_brutos/")
output_n <- length(label_list)
save(label_list, file="label_list.R")
# Tamanho das imagens
width <- 224
height <- 224
target_size <- c(width, height)
rgb <- 3 #color channels
path_train <- "dados_brutos/"
train_data_gen <- image_data_generator(rescale = 1/255,
validation_split = .2)
train_images <- flow_images_from_directory(path_train,
train_data_gen,
subset = 'training',
target_size = target_size,
class_mode = "categorical",
shuffle=F,
seed = 2021)
validation_images <- flow_images_from_directory(path_train,
train_data_gen,
subset = 'validation',
target_size = target_size,
class_mode = "categorical",
seed = 2021)
mod_base <- application_xception(weights = 'imagenet',
include_top = FALSE, input_shape = c(224, 224, 3))
freeze_weights(mod_base)
model %>% evaluate(validation_images)
model <- model_function()
model
model %>% evaluate(validation_images)
path_train <- "dados_brutos/"
train_data_gen <- image_data_generator(rescale = 1/255,
validation_split = .2)
train_images <- flow_images_from_directory(path_train,
train_data_gen,
subset = 'training',
target_size = target_size,
class_mode = "categorical",
shuffle=F,
seed = 2021)
validation_images <- flow_images_from_directory(path_train,
train_data_gen,
subset = 'validation',
target_size = target_size,
class_mode = "categorical",
seed = 2021)
mod_base <- application_xception(weights = 'imagenet',
include_top = FALSE, input_shape = c(224, 224, 3))
freeze_weights(mod_base)
model_function <- function(learning_rate = 0.001,
dropoutrate=0.2, n_dense=1024){
k_clear_session()
model <- keras_model_sequential() %>%
mod_base %>%
layer_global_average_pooling_2d() %>%
layer_dense(units = n_dense) %>%
layer_activation("relu") %>%
layer_dropout(dropoutrate) %>%
layer_dense(units=output_n, activation="softmax")
model %>% compile(
loss = "categorical_crossentropy",
optimizer = optimizer_adam(learning_rate = 0.001),
metrics = "accuracy"
)
return(model)
}
model <- model_function()
model
batch_size <- 32
epochs <- 6
epochs <- 3
hist <- model %>% fit(
train_images,
steps_per_epoch = train_images$n %/% batch_size,
epochs = epochs,
validation_data = validation_images,
validation_steps = validation_images$n %/% batch_size,
verbose = 2
)
model %>% evaluate(validation_images)
test_image <- image_load("teste.jpeg",
target_size = target_size)
View(test_image)
x <- image_to_array(test_image)
x <- array_reshape(x, c(1, dim(x)))
x <- x/255
pred <- model %>% predict(x)
View(pred)
teste_image2 <- image_load('teste2.jpeg',
target_size = target_size)
y <- image_to_array(test_image2)
y <- array_reshape(y, c(1, dim(y)))
y <- y/255
pred <- model %>% predict(y)
y <- image_to_array(test_image2)
test_image2 <- image_load('teste2.jpeg',
target_size = target_size)
x <- image_to_array(test_image)
x <- array_reshape(x, c(1, dim(x)))
x <- x/255
y <- image_to_array(test_image2)
y <- array_reshape(y, c(1, dim(y)))
y <- y/255
pred <- model %>% predict(y)
pred <- data.frame("Gato" = label_list, "Probability" = t(pred))
View(pred)
pred <- data.frame("Animal" = label_list, "Probability" = t(pred))
View(pred)
pred <- model %>% predict(x)
pred <- model %>% predict(y)
pred <- data.frame("Animal" = label_list, "Probability" = t(pred))
View(pred)
pred <- pred[order(pred$Probability, decreasing=T),][1:5,]
View(pred)
pred$Probability <- paste(format(100*pred$Probability,2),"%")
pred
save(model, 'model.rda')
save(model, 'model')
save(model)
save(file = model)
save(file = model())
save(m, file = 'model.rda')
save(model, file = 'model.rda')
rm(model)
pred <- model %>% predict(x)
load('model.rda')
View(model)
pred <- model %>% predict(x)
model %>% evaluate(validation_images)
model <- model_function()
model
?model_function
View(model_function)
model %>% evaluate(validation_images)
pred <- model %>% predict(x)
pred <- model %>% predict(y)
pred <- model %>% predict(x)
hist <- model %>% fit(
train_images,
steps_per_epoch = train_images$n %/% batch_size,
epochs = epochs,
validation_data = validation_images,
validation_steps = validation_images$n %/% batch_size,
verbose = 2
)
model %>% save_model_tf("cat_dog_mod")
load_model_tf(cat_dog_mod)
load_model_tf('cat_dog_mod')
label_listt <- c('cats', 'dogs')
label_list <- c('cats', 'dogs')
rm(label_listt)
pred[1]
pred[2]
pred <- model %>% predict(x)
library(tidyverse)
image <- image_load(file$datapath,
target_size = c(224, 224))
x <- image_to_array(test_image)
x <- array_reshape(x, c(1, dim(x)))
x <- x/255
pred <- model %>% predict(x)
retorno <- ifelse(pred[1]>pred[2], 'É um gato', 'É um cachorro')
return(pred[1])
getOption('rsconnect.max.bundle.size')
options(rsconnect.max.bundle.size=314572800000)
getOption('rsconnect.max.bundle.size')
Sys.setenv(RETICULATE_PYTHON = "/home/max/.virtualenvs/r-tensorflow/bin/python")
reticulate::py_config
globals$py_config
reticulate::globals$py_config
reticulate::py_config
Sys.setenv(RETICULATE_PYTHON = "/home/max/.virtualenvs/r-tensorflow/bin/python")
reticulate::py_config
library(reticulate)
py_config()
Sys.setenv(RETICULATE_PYTHON = "/home/max/.virtualenvs/r-tensorflow/bin/python")
python:         /home/max/.virtualenvs/r-tensorflow/bin/python
reticulate::py_config
reticulate::py_config
reticulate::py_config
library(reticulate)
reticulate::py_config
reticulate:::.globals$py_config
reticulate::virtualenv_create(envname = 'r-tensorflow', python = 'python3')
?virtualenv_install
getOption("reticulate.virtualenv.module")
getOption("reticulate.virtualenv.system_site_packages")
reticulate::py_module_available
reticulate::configure_environment
rsconnect::deployApp()
rsconnect.max.bundle.files
options(rsconnect.max.bundle.files)
